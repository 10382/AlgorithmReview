**为什么要对特征做归一化？**

1. 从梯度下降的角度来说，特征归一化有助于梯度下降更稳定，收敛速度更快。比如说在逻辑回归中，最后的损失函数关于权重的偏导数为 $\frac{\partial L(w)}{\partial w} = \sum_{i=1}^N\left[\sigma(w \cdot x_i) - y_i\right]x_i$，如果 $x_i$ 未做归一化，每个 $x_i$ 可能会很大，会导致要求得的偏导很大，从而导致(在相同学习率的情况下)梯度大幅震荡，模型不容易收敛。
2. 从特征权重的角度来说，特征归一化有助于分析不同特征之间的重要性，消除特征之间单位和尺度差异的影响。比如说在线性回归中，两个相同贡献的特征如果未做归一化，那么训练得到的范围广的特征权重会比较小，在特征分析的时候可能会被忽略。

> 当归一化方法背后的无力意义和几何含义与当前问题的需要相契合时，其对解决该问题就有正向作用，反之，就有反向作用。因此，对于涉及到隐含距离计算的算法，比如 Kmeans、KNN、PCA、SVM，回归模型等，需要对特征做归一化。——《[深入探讨：为什么要做特征归一化/标准化？](https://mp.weixin.qq.com/s/gQKns0AILhtXZDpBk6_myQ)》

**One-hot的作用是什么？为什么不直接使用数字作为表示？**

One-hot 编码的作用是将类别特征转换为计算机可识别并计算的形式，一般用于处理不具备大小关系的特征。

如果直接采用数字表示，会使得模型的训练过程中学习得到本不应该存在的类别大小关系，导致模型过拟合。

**什么是组合特征？如何处理高维组合特征？**(这里的特征组合主要指的是类别特征(Categorical Feature)之间的组合)

特征组合是指将多个类别特征通过与的方式结合起来，从而生成新的类别特征的方法。比如说，经度和纬度特征结合起来就可以变成经纬度特征。

高维组合特征可以通过 Label Encoder 或降维方式去处理，降维中分为矩阵分解，Embedding 等方法。