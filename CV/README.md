

## CNN基础

**CNN 为什么用卷积？除了图像还能用来做什么？**

> 在泛函分析中，卷积（convolution）是透过两个函数 f 和 g 生成第三个函数的一种数学算子，表征函数 f 与经过翻转和平移的 g 的乘积函数所围成的曲边梯形的面积。（g 可当作加权函数）

简单的来说，卷积就是计算一个表征函数滑动的的加权总和(weighted-sum)。

1. 加入了空间共享这个先验信息：通过卷积核，CNN 可以根据卷积核范围内的相邻特征点提取得到图像某个范围内的新特征（加权和）。
2. 满足平移不变性：对于每一个卷积核，其在滑动的过程中，权重是相同的，在图片中的对象经过平移后通过同一个卷积核得到的特征值相同。单个卷积核是用于提取一种特征（形状，边缘，明度等）。
3. <!--特征的自动化提取：通过卷积操作和神经网络的前向后向传播，来自动学习卷积核的权重，从而来实现特征的自动化提取。（属于神经网络的好处）-->

卷积还可用于序列数据（时序，语音）的特征提取（1维卷积），视频流、3D模型的特征提取（3维卷积）。

🚧 **...下面部分施工中...** 👷‍♀️

**卷积的实现方式**

- 滑动窗口：计算较慢，一般不采用。

- Im2col：Caffe，MXNet 都实现了该方法。把卷积过程转化为 GEMM 过程，一般来说，速度较快。

- 快速傅立叶变换 FFT：

- Winograd：CUDNN 中采用了该方法。小卷积核的计算较快。

  缺点：

  - Depth-wise conv 中优势不明显
  - tile 较大时，该方法不适用，transform的计算开销抵消了

Pooling 的作用

- 简化计算量：通过下采样
- 一定的空间不变性

## CNN 发展

**讲一下CNN最近十年的发展历程吧，每一年都有什么新网络的提出，解决了什么问题？**

![CNN Architecture over a timeline](https://www.aismartz.com/blog/wp-content/uploads/2019/10/CNN-Architecture-over-a-timeline.jpg)

> https://www.aismartz.com/blog/cnn-architectures/



**空洞卷积**

1. 扩大感受野
2. 增加平移不变性



